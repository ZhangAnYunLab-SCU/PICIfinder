"""
    OVERVIEW

    PICI_Result_Integration.py

    Functional Overview:
        This module is responsible for integrating PICI prediction results generated from multiple parallel processes,
        performing deduplication and merging operations to produce the final unified result file.

    Main Processing Pipeline:
        1. Result File Merging
           - Combine scattered result files generated by multiple CPU cores into a single file
           - Use cat command to quickly merge all Information.txt files

        2. Data Cleaning and Standardization
           - Read merged result data
           - Set standardized column names for subsequent processing
           - Data type conversion (start/end positions to integer)
           - Sort by sequence name and position

        3. Overlapping Region Deduplication
           - Use double loop to detect overlapping or adjacent PICI regions within the same sequence
           - Handle different types of overlaps based on integration direction:
             * Direction -1: Process duplicate predictions with similar start positions
             * Direction 1: Process duplicate predictions with similar end positions
           - Mark attachment sites of duplicate predictions as 'na'

        4. Final Result Output
           - Delete temporary merged file
           - Remove direction column (used in deduplication)
           - Output formatted final result file

    Output File:
        - all_Infor.txt: Contains all deduplicated PICI prediction results
"""

import os
import sys
from datetime import datetime
import pandas as pd
import subprocess

if __name__ == "__main__":
    seq_file_dire = sys.argv[1]
    subprocess.run('cat '+seq_file_dire+'*Information.txt > '+seq_file_dire+'all_Infor.txt', shell=True)

    if os.path.getsize(seq_file_dire+'all_Infor.txt') != 0:
        Information = pd.read_table(seq_file_dire+'all_Infor.txt', header=None)
        Information.columns = [
            'name','start','end','length','att',
            'att_name','score','condition','dire','VFDB','SARG','Abi'
        ]
        Information['start'] = Information[['start']].astype(int)
        Information['end'] = Information[['end']].astype(int)
        Information = Information.sort_values(by=['name','start','end'], axis=0)
        Information = Information.drop_duplicates(inplace=False)

        # Double loop to handle overlapping or adjacent sequences
        for i in range(len(Information)):
            for j in range(i+1,len(Information)):
                if Information.iloc[i,0] != Information.iloc[j,0]:
                    break
                if (Information.iloc[i,8] == Information.iloc[j,8] and Information.iloc[i,7] != 'uncomplete-int'
                        and Information.iloc[j,7] != 'uncomplete-int'):
                    if ((int(Information.iloc[i,8]) == -1 and int(Information.iloc[j,1]) != int(Information.iloc[i,1])
                        and int(Information.iloc[j,1])-int(Information.iloc[i,1])<2500)
                            or (int(Information.iloc[i,8]) == 1 and int(Information.iloc[j,1]) == int(Information.iloc[i,1]))):
                        Information.iloc[j,4] = 'na'
                    if ((int(Information.iloc[i,8]) == 1 and int(Information.iloc[j,1]) != int(Information.iloc[i,1])
                        and int(Information.iloc[j,2])-int(Information.iloc[i,2])<2500)
                            or (int(Information.iloc[i,8]) == -1 and int(Information.iloc[j,1]) == int(Information.iloc[i,1]))):
                        Information.iloc[i,4] = 'na'

        os.remove(seq_file_dire+'all_Infor.txt')
        Information = Information.drop(['dire'],axis = 1)
        Information.to_csv(seq_file_dire+'all_Infor.txt', sep='\t',index=False)

    time = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
    subprocess.run('echo "\033[33m ['+time+'] \033[0m" "\033[32mThank you for using PICI finder\033[0m"', shell=True)
